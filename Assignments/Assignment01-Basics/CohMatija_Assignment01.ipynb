{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-Coh/M-Coh/blob/main/Assignments/Assignment01-Basics/CohMatija_Assignment01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWD4z-xIdH5V"
      },
      "source": [
        "[<img align=\"right\" width=\"200\" height=\"200\" src=\"https://www.tu-braunschweig.de/typo3conf/ext/tu_braunschweig/Resources/Public/Images/Logos/tu_braunschweig_logo.svg\">](https://www.tu-braunschweig.de/en/)\n",
        "\n",
        "[Mehdi Maboudi](https://www.tu-braunschweig.de/en/igp/staff/mehdi-maboudi) ([m.maboudi@tu-bs.de](m.maboudi@tu-bs.de))\n",
        "\n",
        "[Technical University of Braunschweig](https://www.tu-braunschweig.de/en/)  \n",
        "[Institute of Geodesy and Photogrammetry](https://www.tu-braunschweig.de/igp)  \n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkcoC_o4dH5Y"
      },
      "source": [
        "Considering _Tom Mitchell_ definition:  \n",
        "A computer program is said to learn from experience ùê∏ with respect to some task T and some\n",
        "performance measure ùëÉ, if its performance on ùëá, as measured by ùëÉ, improves with experience ùê∏\n",
        "\n",
        "<font color='red'>## E1 (12 pnt)</font>\n",
        "\n",
        "Select 4 machine learning applications and answer the following questions:\n",
        "- **Task(T)**\n",
        "- **Experience(E)**\n",
        "- **Measure Performance(P)**\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqIF9vXNdH5Z"
      },
      "source": [
        "**Example from the lecture:**\n",
        "\n",
        "**Applications**: Spam filtering\n",
        "  \n",
        "- **Task(T)**: The task is to learn how to classify emails as spam or ham(non-spam).\n",
        "- **Experience(E)**: The dataset is a set consisting of emails and their labels (spam or ham).\n",
        "- **Measure Performance(P)**: count the number of correct predictions to asses the prediction accuracy.\n",
        "\n",
        "_**Category**_. Since we are looking for 2 class labels (spam, non-spam), this is a supervised binary classification.\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "312I86yMdH5a"
      },
      "source": [
        "**Applications01**: Image Recognition of different animals\n",
        "  \n",
        "- **Task(T)**: The task is to classify images into different categories (for example cathegories of different animals: cats, dogs, rabbits...)\n",
        "- **Experience(E)**: A dataset of labeled images where each image is tagged with the correct category.\n",
        "- **Measure Performance(P)**: Accuracy, which is the percentage of correctly classified images.\n",
        "\n",
        "_**Category**_. Supervised multi-class classification.\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vqv2_w4idH5a"
      },
      "source": [
        "**Applications02**: Student Grade Prediction Based on Related Course Grades\n",
        "  \n",
        "- **Task(T)**: To predict a student's grade in a specific course based on their performance in other related courses.\n",
        "- **Experience(E)**: Academic records showing students' grades in multiple courses, where the relationship between course performances can be learned.\n",
        "- **Measure Performance(P)**: Error between predicted and actual grades\n",
        "\n",
        "_**Category**_. Supervised regression (for numerical grade prediction, for example from 0 to 100)\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0XVPTTtdH5b"
      },
      "source": [
        "**Applications03**: House Price Prediction\n",
        "  \n",
        "- **Task(T)**: To predict the selling price of a house based on its features (size, location, number of rooms...)\n",
        "- **Experience(E)**: Data of house sales including features like size, location, number of rooms and their sale prices.\n",
        "- **Measure Performance(P)**: Error between predicted and actual prices\n",
        "\n",
        "_**Category**_. Supervised regression\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-ARUtcedH5b"
      },
      "source": [
        "**Applications04**: Segmenting clients based on purchase behavior for targeted marketing\n",
        "  \n",
        "- **Task(T)**: Segmenting clients based on their purchases so that you can design a different marketing strategy\n",
        "for each segment.\n",
        "- **Experience(E)**: purchase data and categories of products.\n",
        "- **Measure Performance(P)**: metrics that measure\n",
        "compactness (how close points within the same cluster are to each other).\n",
        "\n",
        "_**Category**_. Unsupervised clustering\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8pCrLYadH5c"
      },
      "source": [
        "<font color='red'>## E2 (20 pnt)</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XS-LtBGtdH5c"
      },
      "source": [
        "Standardization of a dataset is a common requirement for many machine learning estimators: they might behave badly if the individual features do not more or less look like standard normally distributed data (e.g. Gaussian with 0 mean and unit variance).  \n",
        "In this Exercise we will write a very simplified and naive feature normalizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lQPmfNndH5d"
      },
      "source": [
        "Given the function below called `normalizer` do the following step:\n",
        " - **ducumentation** (4pnts)\n",
        " - **function implementation** (12pnts)  \n",
        "      Normalizing the elements of a 2D array:\n",
        "    \n",
        "            For each element of a column:\n",
        "            Subtract the mean and devide it by variance (this is called Centering and scaling)\n",
        "\n",
        "            Considering \"i\"th element of \"j\"th column of array X as x[i,j],\n",
        "            transforme x[i,j] to z[i,j]:\n",
        "\n",
        "            z[i,j] = (x[i,j] - u) / s\n",
        "\n",
        "            where u is the mean of the column j and s is the standard deviation of that column.\n",
        " - **test your function** (4pnts). Do not forget edge cases\n",
        "      \n",
        "You can get some hints from folowing link:   \n",
        "**But do not use it directly and write your code just with low level numpy and python commands**  \n",
        "[sklearn.preprocessing.StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2iPUFKodH5e"
      },
      "outputs": [],
      "source": [
        "def normalizer(X):\n",
        "    \"\"\"\n",
        "    Documentation:\n",
        "        function description: This function standardizes (normalizes) a 2D numpy array by transforming each column\n",
        "        so that it has mean = 0 and standard deviation = 1.\n",
        "        The transformation is performed column-wise:\n",
        "            z[i,j] = (x[i,j] - mean_j) / std_j,\n",
        "        for every column j of the input array x ve calculate the mean and standard deviation of column j and\n",
        "        apply the transformation to the entire column.\n",
        "\n",
        "        inputs: A 2D NumPy array of shape (n_samples, n_features) containing numerical data.\n",
        "        Each row represents one sample.\n",
        "        Each column represents one feature (variable) that will be standardized.\n",
        "        The array must contain only numeric values.\n",
        "        outputs: A 2D NumPy array of the same shape as X.\n",
        "        Each column of X_transformed has been standardized to have:\n",
        "        mean = 0 and standard deviation = 1\n",
        "        The output contains the normalized version of the input data.\n",
        "    \"\"\"\n",
        "    ### Start of your code ##\n",
        "\n",
        "    # check the inputs\n",
        "    if not isinstance(X, np.ndarray):\n",
        "        raise TypeError(\"Input X must be a numpy array\")\n",
        "    if X.ndim != 2:\n",
        "        raise ValueError(\"Input X must be a 2D array\")\n",
        "    if not np.issubdtype(X.dtype, np.number):\n",
        "        raise TypeError(\"All elements in X must be numeric (int or float)\")\n",
        "    # main body\n",
        "    X_transformed = X.copy().astype(float)  #to avoid modifying original\n",
        "\n",
        "    n_samples, n_features = X.shape #number of rows and columns\n",
        "\n",
        "    for j in range(n_features):\n",
        "        col = X[:, j]\n",
        "        mean = np.mean(col)\n",
        "        std = np.std(col)\n",
        "\n",
        "        # avoid division by zero if std = 0\n",
        "        if std == 0:\n",
        "            X_transformed[:, j] = 0\n",
        "        else:\n",
        "            X_transformed[:, j] = (col - mean) / std\n",
        "    ### End of your code ##\n",
        "\n",
        "    return X_transformed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8A_vMZedH5e"
      },
      "source": [
        "Add your tests in separate cells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hn_nGmuZdH5f",
        "outputId": "db914b5e-f1e0-4e20-bd4e-7e6fb0e0332f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test 1 - Original:\n",
            " [[1. 2. 3.]\n",
            " [4. 5. 6.]\n",
            " [7. 8. 9.]]\n",
            "Test 1 - Normalized:\n",
            " [[-1.22474487 -1.22474487 -1.22474487]\n",
            " [ 0.          0.          0.        ]\n",
            " [ 1.22474487  1.22474487  1.22474487]]\n",
            "Column means: [0. 0. 0.]\n",
            "Column stds: [1. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# --- Test 1: normal example ---\n",
        "X1 = np.array([\n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "    [7, 8, 9]\n",
        "], dtype=float)\n",
        "\n",
        "Z1 = normalizer(X1)\n",
        "print(\"Test 1 - Original:\\n\", X1)\n",
        "print(\"Test 1 - Normalized:\\n\", Z1)\n",
        "print(\"Column means:\", np.mean(Z1, axis=0))  # ~0\n",
        "print(\"Column stds:\", np.std(Z1, axis=0))    # ~1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpJKzyO1dH5f",
        "outputId": "0d52a5a3-358a-4806-c8fb-2d65b654c031"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test 2 - Edge case (constant column):\n",
            " [[ 0.         -1.22474487]\n",
            " [ 0.          0.        ]\n",
            " [ 0.          1.22474487]]\n"
          ]
        }
      ],
      "source": [
        "# --- Test 2: edge case - column with all identical values ---\n",
        "X2 = np.array([\n",
        "    [5, 1],\n",
        "    [5, 2],\n",
        "    [5, 3]\n",
        "], dtype=float)\n",
        "\n",
        "Z2 = normalizer(X2)\n",
        "print(\"\\nTest 2 - Edge case (constant column):\\n\", Z2)\n",
        "# First column is constant -> all values become 0\n",
        "# Second column is normalized normally"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zM_cAZHdH5g"
      },
      "source": [
        "<font color='red'>## E3 (30 pnt)</font>  \n",
        "Transform features by scaling each feature to a given range."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e1L3tXvdH5g"
      },
      "source": [
        "Write a function to transform features by scaling each feature to a given range.\n",
        "\n",
        "- Understanding the problem(10)  \n",
        "- Documentation (4pnts)  \n",
        "- Function implementation (12pnts)  \n",
        "- Test your function (4pnts)\n",
        "- selecting proper name for function and variables (3pnts)\n",
        "\n",
        "You should check the following link to understand the problem:  \n",
        "**But do not use it directly and write your code just with low level numpy and python commands**  \n",
        "[sklearn.preprocessing.MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-72QeBOpdH5g"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def min_max_scaler(X, feature_range=(0, 1)):\n",
        "    \"\"\"\n",
        "    Documentation:\n",
        "        Function description: This function scales each feature (column) of a 2D numpy array to a given range.\n",
        "        The transformation is performed column-wise:\n",
        "            x_scaled[i,j] = (x[i,j] - min_j) / (max_j - min_j) * (max_range - min_range) + min_range\n",
        "        where min_j and max_j are the minimum and maximum values of column j, and\n",
        "        min_range and max_range define the desired output range.\n",
        "\n",
        "        Inputs:\n",
        "            X : A 2D NumPy array of shape (n_samples, n_features) containing numerical data.\n",
        "                Each row represents one sample.\n",
        "                Each column represents one feature (variable) to be scaled.\n",
        "                The array must contain only numeric values.\n",
        "            feature_range : interval (min_range, max_range), the desired range of transformed data.\n",
        "                Default is (0, 1).\n",
        "\n",
        "        Outputs:\n",
        "            X_scaled : A 2D NumPy array of the same shape as X.\n",
        "                Each column has been scaled to the specified range (interval).\n",
        "    \"\"\"\n",
        "    ### Start of your code ###\n",
        "\n",
        "    # --- check inputs ---\n",
        "    if not isinstance(X, np.ndarray):\n",
        "        raise TypeError(\"Input X must be a numpy array\")\n",
        "    if X.ndim != 2:\n",
        "        raise ValueError(\"Input X must be a 2D array\")\n",
        "    if not np.issubdtype(X.dtype, np.number):\n",
        "        raise TypeError(\"All elements in X must be numeric (int or float)\")\n",
        "    if not isinstance(feature_range, tuple) or len(feature_range) != 2:\n",
        "        raise ValueError(\"feature_range must be a tuple of length 2\")\n",
        "\n",
        "    min_range, max_range = feature_range\n",
        "    if min_range >= max_range:\n",
        "        raise ValueError(\"feature_range[0] must be smaller than feature_range[1]\")\n",
        "\n",
        "    # --- main body ---\n",
        "    X_scaled = X.copy().astype(float)  # avoid modifying original\n",
        "    n_samples, n_features = X.shape\n",
        "\n",
        "    for j in range(n_features):\n",
        "        col = X[:, j]\n",
        "        col_min = np.min(col)\n",
        "        col_max = np.max(col)\n",
        "        # avoid division by zero if col_min == col_max\n",
        "        if col_max == col_min:\n",
        "            # set to middle of range (avg) if all values are identical\n",
        "            X_scaled[:, j] = (min_range + max_range) / 2\n",
        "        else:\n",
        "            X_scaled[:, j] = (col - col_min) / (col_max - col_min) * (max_range - min_range) + min_range\n",
        "\n",
        "    ### End of your code ###\n",
        "    return X_scaled\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGJTP2j2dH5g",
        "outputId": "66c9eec5-d30e-448e-d93d-03ff92601323"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test 1 - Scaled:\n",
            " [[0.  0.  0. ]\n",
            " [0.5 0.5 0.5]\n",
            " [1.  1.  1. ]]\n",
            "\n",
            "Test 2 - Edge case (constant column):\n",
            " [[ 0. -1.]\n",
            " [ 0.  0.]\n",
            " [ 0.  1.]]\n"
          ]
        }
      ],
      "source": [
        "# Test 1: basic example\n",
        "X1 = np.array([\n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "    [7, 8, 9]\n",
        "], dtype=float)\n",
        "Z1 = min_max_scaler(X1, feature_range=(0, 1))\n",
        "print(\"Test 1 - Scaled:\\n\", Z1)\n",
        "\n",
        "# Test 2: edge case - constant column\n",
        "X2 = np.array([\n",
        "    [5, 1],\n",
        "    [5, 2],\n",
        "    [5, 3]\n",
        "], dtype=float)\n",
        "Z2 = min_max_scaler(X2, feature_range=(-1, 1))\n",
        "print(\"\\nTest 2 - Edge case (constant column):\\n\", Z2)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}